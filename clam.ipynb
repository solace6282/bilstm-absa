{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, ConvLSTM1D\n",
    "from keras.datasets import imdb \n",
    "from keras.utils import pad_sequences\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique_words = 10000 # cut texts after this number of words\n",
    "maxlen = 200\n",
    "batch_size = 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = imdb.load_data(num_words=n_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, 128, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "# model.add(ConvLSTM1D(2, 1))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 210s 1s/step - loss: 0.6679 - accuracy: 0.6730 - val_loss: 0.4717 - val_accuracy: 0.8120\n",
      "[0.6678797602653503]\n",
      "[0.6729599833488464]\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=1,\n",
    "            validation_data=[x_test, y_test])\n",
    "print(history.history['loss'])\n",
    "print(history.history['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_23\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"bidirectional_27\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 128)\n    \n    Call arguments received by layer \"sequential_23\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=string)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\proj\\bilstm\\clam.ipynb Cell 9\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/proj/bilstm/clam.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mpredict([\u001b[39m\"\u001b[39;49m\u001b[39mTest\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filez08a5mu3.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_23\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"bidirectional_27\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 128)\n    \n    Call arguments received by layer \"sequential_23\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=string)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: dense_1. Existing layers are: ['bidirectional_36'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\proj\\bilstm\\clam.ipynb Cell 9\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/proj/bilstm/clam.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# layer_name = 'bidirectional_2'\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/proj/bilstm/clam.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# intermediate_layer_model = Model(inputs=model.input,\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/proj/bilstm/clam.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#                                  outputs=model.get_layer(layer_name).output)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/proj/bilstm/clam.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# intermediate_output = intermediate_layer_model.predict(\"the movie is good .\")\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/proj/bilstm/clam.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/proj/bilstm/clam.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m intermediate_layer_model \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39minput,\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/proj/bilstm/clam.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                                        outputs\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mget_layer(\u001b[39m\"\u001b[39;49m\u001b[39mdense_1\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39moutput)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/proj/bilstm/clam.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m intermediate_output \u001b[39m=\u001b[39m intermediate_layer_model(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/proj/bilstm/clam.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mtype\u001b[39m(torch\u001b[39m.\u001b[39mFloatTensor(intermediate_output\u001b[39m.\u001b[39mnumpy()))\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:3275\u001b[0m, in \u001b[0;36mModel.get_layer\u001b[1;34m(self, name, index)\u001b[0m\n\u001b[0;32m   3273\u001b[0m         \u001b[39mif\u001b[39;00m layer\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m name:\n\u001b[0;32m   3274\u001b[0m             \u001b[39mreturn\u001b[39;00m layer\n\u001b[1;32m-> 3275\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   3276\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo such layer: \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m. Existing layers are: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(layer\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3278\u001b[0m     )\n\u001b[0;32m   3279\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   3280\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mProvide either a layer name or layer index at \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m`get_layer`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3281\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: No such layer: dense_1. Existing layers are: ['bidirectional_36']."
     ]
    }
   ],
   "source": [
    "# layer_name = 'bidirectional_2'\n",
    "# intermediate_layer_model = Model(inputs=model.input,\n",
    "#                                  outputs=model.get_layer(layer_name).output)\n",
    "# intermediate_output = intermediate_layer_model.predict(\"the movie is good .\")\n",
    "\n",
    "\n",
    "\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                       outputs=model.get_layer(\"dense_1\").output)\n",
    "intermediate_output = intermediate_layer_model(data)\n",
    "type(torch.FloatTensor(intermediate_output.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 587ms/step\n",
      "Text 0: This movie is fantastic!\n",
      "Sentiment: negative, Score: [0.1056781]\n",
      "\n",
      "Text 1: I hated this movie.\n",
      "Sentiment: negative, Score: [0.14753363]\n",
      "\n",
      "Text 2: The acting was okay, but the plot was boring.\n",
      "Sentiment: negative, Score: [0.12623395]\n",
      "\n",
      "Text 3: I loved the book, but the movie was a disappointment.\n",
      "Sentiment: negative, Score: [0.14439166]\n",
      "\n",
      "Text 4: The special effects were amazing, but the story was weak.\n",
      "Sentiment: negative, Score: [0.12880972]\n",
      "\n",
      "Text 5: Movie was amazing!\n",
      "Sentiment: negative, Score: [0.04176935]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Define the test data\n",
    "texts = [\n",
    "    \"This movie is fantastic!\",\n",
    "    \"I hated this movie.\",\n",
    "    \"The acting was okay, but the plot was boring.\",\n",
    "    \"I loved the book, but the movie was a disappointment.\",\n",
    "    \"The special effects were amazing, but the story was weak.\",\n",
    "    \"Movie was amazing!\"\n",
    "]\n",
    "\n",
    "# Tokenize the test data\n",
    "max_features = 5000\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "data = pad_sequences(sequences, maxlen=200)\n",
    "\n",
    "# Predict the sentiment\n",
    "predictions = model.predict(data)\n",
    "\n",
    "# Print the predictions\n",
    "for i, prediction in enumerate(predictions):\n",
    "    sentiment = 'positive' if prediction > 0.5 else 'negative'\n",
    "    print(f\"Text {i}: {texts[i]}\")\n",
    "    print(f\"Sentiment: {sentiment}, Score: {prediction}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2  3  4  5  6  7  8  9 10]]]\n",
      "1/1 [==============================] - 1s 621ms/step\n",
      "(1, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(10, return_sequences=True), input_shape=(1, 10)))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "# model.add(Bidirectional(LSTM(32)))\n",
    "# model.add(Activation('relu'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "y = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape((1,1,10))\n",
    "print(y)\n",
    "# make and show prediction\n",
    "print(tf.constant(model.predict(y)).get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (1,2)\n",
    "c, d = a\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
